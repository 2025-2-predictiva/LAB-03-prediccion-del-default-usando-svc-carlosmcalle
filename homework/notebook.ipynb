{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gzip\n",
        "import json\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    balanced_accuracy_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        ")"
      ],
      "metadata": {
        "id": "d_YPz0rPTk8Z"
      },
      "id": "d_YPz0rPTk8Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definimos algunas funciones a usar\n",
        "\n",
        "def verificar_carpetas():\n",
        "    \"\"\"Asegura que los directorios de salida existan.\"\"\"\n",
        "    os.makedirs(\"../files/models\", exist_ok=True)\n",
        "    os.makedirs(\"../files/output\", exist_ok=True)\n",
        "\n",
        "def cargar_datos_fuente():\n",
        "    \"\"\"Carga los DataFrames de entrenamiento y prueba.\"\"\"\n",
        "    train_path = \"../files/input/train_data.csv.zip\"\n",
        "    test_path = \"../files/input/test_data.csv.zip\"\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "    return train_df, test_df\n",
        "\n",
        "def recuperar_modelo(path=\"../files/models/model.pkl.gz\"):\n",
        "    \"\"\"Carga el estimador guardado si existe, sino devuelve None.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        return None\n",
        "    with gzip.open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def guardar_modelo_comprimido(estimator, path=\"../files/models/model.pkl.gz\"):\n",
        "    \"\"\"Guarda el estimador comprimido con gzip.\"\"\"\n",
        "    verificar_carpetas()\n",
        "    with gzip.open(path, \"wb\") as f:\n",
        "        pickle.dump(estimator, f)\n",
        "\n",
        "\n",
        "def preparar_df(df):\n",
        "    \"\"\"Limpia y transforma un DataFrame (manejo de columnas y valores atípicos).\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # renombrar\n",
        "    if \"default payment next month\" in df.columns:\n",
        "        df = df.rename(columns={\"default payment next month\": \"default\"})\n",
        "\n",
        "    if \"ID\" in df.columns:\n",
        "        df = df.drop(columns=[\"ID\"])\n",
        "\n",
        "    if \"EDUCATION\" in df.columns:\n",
        "        df[\"EDUCATION\"] = pd.to_numeric(df[\"EDUCATION\"], errors=\"coerce\")\n",
        "        df.loc[df[\"EDUCATION\"].isna(), \"EDUCATION\"] = 4\n",
        "        df[\"EDUCATION\"] = df[\"EDUCATION\"].astype(int)\n",
        "        df.loc[df[\"EDUCATION\"] > 4, \"EDUCATION\"] = 4\n",
        "        df.loc[df[\"EDUCATION\"] == 0, \"EDUCATION\"] = 4\n",
        "\n",
        "    # Eliminar registros con valor 0 en MARRIAGE\n",
        "    df.drop(df[df[\"MARRIAGE\"] == 0].index, inplace=True)\n",
        "    df = df.dropna()\n",
        "\n",
        "    return df\n",
        "\n",
        "def obtener_splits(train_df, test_df):\n",
        "    \"\"\"\n",
        "    Aplica preparar_df a los datos de entrenamiento y prueba\n",
        "    y retorna x_train, y_train, x_test, y_test\n",
        "    \"\"\"\n",
        "    train_clean = preparar_df(train_df)\n",
        "    test_clean = preparar_df(test_df)\n",
        "\n",
        "    x_train = train_clean.drop(columns=[\"default\"])\n",
        "    y_train = train_clean[\"default\"]\n",
        "\n",
        "    x_test = test_clean.drop(columns=[\"default\"])\n",
        "    y_test = test_clean[\"default\"]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n"
      ],
      "metadata": {
        "id": "mNp8Li5yT6fm"
      },
      "id": "mNp8Li5yT6fm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Funciones de Componentes del modelo\n",
        "\n",
        "def construir_pipeline(feature_columns):\n",
        "\n",
        "    categorical_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
        "    # Las demás columnas se consideran numéricas\n",
        "    numeric_features = [c for c in feature_columns if c not in categorical_features]\n",
        "\n",
        "    categorical_pipeline = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ])\n",
        "\n",
        "    numeric_pipeline = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"cat\", categorical_pipeline, categorical_features),\n",
        "            (\"num\", numeric_pipeline, numeric_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('pca', PCA(n_components=None)),\n",
        "        ('selector', SelectKBest(score_func=f_classif)),\n",
        "        ('classifier', SVC(random_state=123))\n",
        "        ], verbose=False\n",
        "    )\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "def crear_busqueda_grid(estimator, param_grid, cv=10):\n",
        "    \"\"\"Crea y configura el objeto GridSearchCV.\"\"\"\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=estimator,\n",
        "        param_grid=param_grid,\n",
        "        cv=cv,\n",
        "        scoring=\"balanced_accuracy\",\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        return_train_score=True\n",
        "    )\n",
        "    return grid_search\n"
      ],
      "metadata": {
        "id": "Ac77nZ19Ub8A"
      },
      "id": "Ac77nZ19Ub8A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Funciones de Ejecución y Validación\n",
        "def entrenar_y_comparar(grid_search):\n",
        "    \"\"\"\n",
        "    Entrena el modelo, compara el score con el modelo guardado,\n",
        "    y guarda si el nuevo modelo es mejor.\n",
        "    \"\"\"\n",
        "    train_df, test_df = cargar_datos_fuente()\n",
        "    x_train, y_train, x_test, y_test = obtener_splits(train_df, test_df)\n",
        "\n",
        "    # Entrenar\n",
        "    grid_search.fit(x_train, y_train)\n",
        "\n",
        "    # Cargar modelo guardado\n",
        "    saved = recuperar_modelo()\n",
        "    current_score = balanced_accuracy_score(y_test, grid_search.predict(x_test))\n",
        "\n",
        "    # Determinar el score del modelo guardado\n",
        "    if saved is not None:\n",
        "        try:\n",
        "            saved_score = balanced_accuracy_score(y_test, saved.predict(x_test))\n",
        "        except Exception:\n",
        "            # Si el objeto guardado no tiene predict\n",
        "            saved_score = -1.0\n",
        "    else:\n",
        "        saved_score = -1.0\n",
        "\n",
        "    # Guardar si el score actual es igual o mejor\n",
        "    if current_score >= saved_score:\n",
        "        guardar_modelo_comprimido(grid_search)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "def ejecutar_entrenamiento_principal():\n",
        "    train_df, test_df = cargar_datos_fuente()\n",
        "    # Usamos solo x_train para obtener los nombres de las columnas\n",
        "    x_train, _, _, _ = obtener_splits(train_df, test_df)\n",
        "\n",
        "    pipeline = construir_pipeline(feature_columns=x_train.columns.tolist())\n",
        "\n",
        "    param_grid ={\n",
        "    'selector__k': [15, 17, 20, 'all'],\n",
        "    'classifier__gamma': [0.01, 0.1, 1],\n",
        "    }\n",
        "\n",
        "    gs = crear_busqueda_grid(estimator=pipeline, param_grid=param_grid, cv=10)\n",
        "    entrenar_y_comparar(gs)\n",
        "\n",
        "\n",
        "def validar_modelo_y_metricas():\n",
        "    verificar_carpetas()\n",
        "    train_df, test_df = cargar_datos_fuente()\n",
        "    x_train, y_train, x_test, y_test = obtener_splits(train_df, test_df)\n",
        "\n",
        "    # Cargar modelo (gzip)\n",
        "    estimator = recuperar_modelo()\n",
        "    if estimator is None:\n",
        "        raise FileNotFoundError(\"No se encontró modelo en files/models/model.pkl.gz\")\n",
        "\n",
        "    # Predicciones\n",
        "    y_train_pred = estimator.predict(x_train)\n",
        "    y_test_pred = estimator.predict(x_test)\n",
        "\n",
        "    metrics = []\n",
        "\n",
        "    # Métricas de entrenamiento\n",
        "    train_metrics = {\n",
        "        \"type\": \"metrics\",\n",
        "        \"dataset\": \"train\",\n",
        "        \"precision\": precision_score(y_train, y_train_pred, zero_division=0),\n",
        "        \"balanced_accuracy\": balanced_accuracy_score(y_train, y_train_pred),\n",
        "        \"recall\": recall_score(y_train, y_train_pred, zero_division=0),\n",
        "        \"f1_score\": f1_score(y_train, y_train_pred, zero_division=0),\n",
        "    }\n",
        "    metrics.append(train_metrics)\n",
        "\n",
        "    # Métricas de prueba\n",
        "    test_metrics = {\n",
        "        \"type\": \"metrics\",\n",
        "        \"dataset\": \"test\",\n",
        "        \"precision\": precision_score(y_test, y_test_pred, zero_division=0),\n",
        "        \"balanced_accuracy\": balanced_accuracy_score(y_test, y_test_pred),\n",
        "        \"recall\": recall_score(y_test, y_test_pred, zero_division=0),\n",
        "        \"f1_score\": f1_score(y_test, y_test_pred, zero_division=0),\n",
        "    }\n",
        "    metrics.append(test_metrics)\n",
        "\n",
        "    # Matriz de confusión train\n",
        "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
        "    cm_train_dict = {\n",
        "        \"type\": \"cm_matrix\",\n",
        "        \"dataset\": \"train\",\n",
        "        \"true_0\": {\"predicted_0\": int(cm_train[0, 0]), \"predicted_1\": int(cm_train[0, 1])},\n",
        "        \"true_1\": {\"predicted_0\": int(cm_train[1, 0]), \"predicted_1\": int(cm_train[1, 1])},\n",
        "    }\n",
        "    metrics.append(cm_train_dict)\n",
        "\n",
        "    # Matriz de confusión test\n",
        "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
        "    cm_test_dict = {\n",
        "        \"type\": \"cm_matrix\",\n",
        "        \"dataset\": \"test\",\n",
        "        \"true_0\": {\"predicted_0\": int(cm_test[0, 0]), \"predicted_1\": int(cm_test[0, 1])},\n",
        "        \"true_1\": {\"predicted_0\": int(cm_test[1, 0]), \"predicted_1\": int(cm_test[1, 1])},\n",
        "    }\n",
        "    metrics.append(cm_test_dict)\n",
        "\n",
        "    # Guardar JSONL\n",
        "    out_path = \"../files/output/metrics.json\"\n",
        "    with open(out_path, \"w\") as f:\n",
        "        for m in metrics:\n",
        "            f.write(json.dumps(m) + \"\\n\")\n",
        "\n",
        "    print(f\"Métricas guardadas en {out_path}\")\n"
      ],
      "metadata": {
        "id": "dhOvUYmFUg67"
      },
      "id": "dhOvUYmFUg67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Si se ejecuta el script, entrena y luego comprueba\n",
        "    verificar_carpetas()\n",
        "    ejecutar_entrenamiento_principal()\n",
        "    validar_modelo_y_metricas()"
      ],
      "metadata": {
        "id": "2et497qtThGe"
      },
      "id": "2et497qtThGe",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}